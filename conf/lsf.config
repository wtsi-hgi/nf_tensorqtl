// Configuration for Load Sharing Facility (LSF) workload management platform

executor {
    name = 'lsf'

    // Set total number of jobs that can be simultaneously run
    queueSize = 1000
    killBatchSize = 1000
    perJobMemLimit = true

    // Set perJobMemLimit to true. See:
    // * https://github.com/nextflow-io/nextflow/issues/123
    // * https://gitter.im/nextflow-io/nextflow/archives/2018/02/09
} // end executor

conda {
    cacheDir = "${projectDir}/../nf_cacheDir"
}

singularity {
    enabled     = true
    autoMounts  = true
    // USER could set this via NXF_SINGULARITY_CACHEDIR
    cacheDir = '/lustre/scratch123/hgi/projects/ukbb_scrna/pipelines/singularity_images'
    runOptions = '--containall --dns 172.18.255.1,172.18.255.2,172.18.255.3'
    envWhitelist = 'HOSTNAME,SSH_CONNECTION,SSH_CLIENT,CVS_RSH,http_proxy,https_proxy,HTTP_PROXY'
}

process {
    executor = 'lsf'
    disk = 10.GB

    queue = 'normal'
    // native configuration options
    //clusterOptions = { "-R \"select[mem>${task.memory.toMega()}]\"" }
    //clusterOptions = { "-R \"span[hosts=1]\"" }

    // specific settings for processes with specific labels such as
    // big_mem, short, long
    //withLabel: big_mem {
    //    cpus = 16
    //    memory = 64.GB
    //    queue = 'hugemem'
    //}
    withLabel: long_job {
        queue = 'long'
    }
    withLabel: gpu {
        cpus = 1
        queue = 'gpu-normal'
        memory = 8.GB
        clusterOptions = {"-M ${task.memory.toMega()} -R \"select[ngpus>0 && mem>=${task.memory.toMega()}] rusage[ngpus_physical=1.00,mem=${task.memory.toMega()}] span[ptile=1]\" -gpu \"mode=exclusive_process\""}
        containerOptions = {
            workflow.containerEngine == "singularity" ? '--nv':
            ( workflow.containerEngine == "docker" ? '--gpus all': null )
        }
    }
} // end process
